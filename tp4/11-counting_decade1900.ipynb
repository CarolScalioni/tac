{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7612caae-bf4a-4bae-8f4b-957bcba9a004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yake\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yake\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image\n",
    "\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "\n",
    "import sys\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import sys\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65367f4-551a-4218-946f-1737c249716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675dfa06-e1e6-4e87-8a7a-6b0446b8283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8136021-9927-40cb-b2f4-31d86aa9abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/txt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0981312-3c7a-4fcc-b0a5-d3d3c8cdfd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0c8d2-1335-4ebf-98a3-279189209f7a",
   "metadata": {},
   "source": [
    "## Choisir une décennie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a75160d0-4635-4865-86eb-b62d9ba1d1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DECADE = '1900'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1dd8e-d5e6-4bf0-9248-92b073965e09",
   "metadata": {},
   "source": [
    "## Charger tous les  fichiers de la décennie et en créer une liste de textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8c1184-1276-418d-92c8-ca9cc985464c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bxl_1900_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1900_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1900_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1900_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1900_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1900_Tome_I1_Part_6.txt',\n",
       " 'Bxl_1900_Tome_I1_Part_7.txt',\n",
       " 'Bxl_1900_Tome_I1_Part_8.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_1.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_10.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_11.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_12.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_13.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_14.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_2.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_3.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_4.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_5.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_6.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_7.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_8.txt',\n",
       " 'Bxl_1900_Tome_I2_Part_9.txt',\n",
       " 'Bxl_1900_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1900_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_10.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_6.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_7.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_8.txt',\n",
       " 'Bxl_1901_Tome_I1_Part_9.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_1.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_10.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_11.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_12.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_13.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_14.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_15.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_2.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_3.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_4.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_5.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_6.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_7.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_8.txt',\n",
       " 'Bxl_1901_Tome_I2_Part_9.txt',\n",
       " 'Bxl_1902_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1902_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1902_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1902_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1902_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1902_Tome_I1_Part_6.txt',\n",
       " 'Bxl_1902_Tome_I1_Part_7.txt',\n",
       " 'Bxl_1902_Tome_I2_2_Part_1.txt',\n",
       " 'Bxl_1902_Tome_I2_2_Part_2.txt',\n",
       " 'Bxl_1902_Tome_I2_2_Part_3.txt',\n",
       " 'Bxl_1902_Tome_I2_2_Part_4.txt',\n",
       " 'Bxl_1902_Tome_I2_2_Part_5.txt',\n",
       " 'Bxl_1902_Tome_I2_2_Part_6.txt',\n",
       " 'Bxl_1902_Tome_I2_2_Part_7.txt',\n",
       " 'Bxl_1902_Tome_I2_2_Part_8.txt',\n",
       " 'Bxl_1902_Tome_I2_2_Part_9.txt',\n",
       " 'Bxl_1902_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1902_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1903_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1903_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1903_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1903_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1903_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1903_Tome_I1_Part_6.txt',\n",
       " 'Bxl_1903_Tome_I1_Part_7.txt',\n",
       " 'Bxl_1903_Tome_I1_Part_8.txt',\n",
       " 'Bxl_1903_Tome_I1_Part_9.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_1.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_10.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_2.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_3.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_4.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_5.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_6.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_7.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_8.txt',\n",
       " 'Bxl_1903_Tome_I2_1_Part_9.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_1.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_10.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_11.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_12.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_2.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_3.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_4.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_5.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_6.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_7.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_8.txt',\n",
       " 'Bxl_1903_Tome_I2_2_Part_9.txt',\n",
       " 'Bxl_1903_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1903_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_1.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_10.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_11.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_12.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_13.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_14.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_15.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_16.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_17.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_18.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_2.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_3.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_4.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_5.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_6.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_7.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_8.txt',\n",
       " 'Bxl_1904_Tome_I2_Part_9.txt',\n",
       " 'Bxl_1904_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1904_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_10.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_11.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_12.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_6.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_7.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_8.txt',\n",
       " 'Bxl_1905_Tome_I1_Part_9.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_1.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_10.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_11.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_12.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_13.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_14.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_2.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_3.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_4.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_5.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_6.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_7.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_8.txt',\n",
       " 'Bxl_1905_Tome_I2_Part_9.txt',\n",
       " 'Bxl_1905_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1905_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1905_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_10.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_11.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_12.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_13.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_6.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_7.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_8.txt',\n",
       " 'Bxl_1906_Tome_I1_Part_9.txt',\n",
       " 'Bxl_1906_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1906_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1906_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_1.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_10.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_11.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_12.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_13.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_14.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_15.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_16.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_2.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_3.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_4.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_5.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_6.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_7.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_8.txt',\n",
       " 'Bxl_1907_Tome_I2_Part_9.txt',\n",
       " 'Bxl_1907_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1907_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1907_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_10.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_11.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_12.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_13.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_6.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_7.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_8.txt',\n",
       " 'Bxl_1908_Tome_I1_Part_9.txt',\n",
       " 'Bxl_1908_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1908_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1908_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_1.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_10.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_2.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_3.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_4.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_5.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_6.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_7.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_8.txt',\n",
       " 'Bxl_1909_Tome_I2_1_Part_9.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_1.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_10.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_2.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_3.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_4.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_5.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_6.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_7.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_8.txt',\n",
       " 'Bxl_1909_Tome_I2_2_Part_9.txt',\n",
       " 'Bxl_1909_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1909_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1909_Tome_II1_Part_3.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_1.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_10.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_2.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_3.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_4.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_5.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_6.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_7.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_8.txt',\n",
       " 'Lkn_1901_Tome_RptAn_Part_9.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_path = \"../data/txt/\"\n",
    "\n",
    "#files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "#print(files)\n",
    "\n",
    "# Lister les fichiers de cette année\n",
    "data_path = '../data'\n",
    "txt_path = '../data/txt'\n",
    "txts = [f for f in os.listdir(txt_path) if os.path.isfile(os.path.join(txt_path, f)) and f\"_{DECADE[:-1]}\" in f]\n",
    "txts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb16ee1-2472-4c9a-a0c6-d8107f59c90d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c3b018-a348-428f-90d5-b024aa1df739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stocker le contenu de ces fichiers dans une liste\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(os.path.join(txt_path, txt), 'r') as f:\n",
    "        content_list.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a867c8-48b8-4bc4-8abf-c9e423bc2c28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bxl_1900_Tome_I1_Part_1.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer les 200 premiers caractères du contenu du premier fichier\n",
    "txts[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b5b2f9c-19b2-4021-9517-4ec25de6dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrire tout le contenu dans un fichier temporaire\n",
    "temp_path = '../data/tmp'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "with open(os.path.join(temp_path, f'{DECADE}.txt'), 'w') as f:\n",
    "    f.write(' '.join(content_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dec4332b-16c0-4c7d-b404-cca6e7910bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textract\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "544e06fd-758a-4cad-84e7-ed292a9e7aca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"VILLE\\n\\nDE\\n\\nBULLETIN\\n\\nBRUXELLES.\\n\\nCOMMUNAL\\n\\nANNÉE\\n\\nP R E M I È R E\\n\\nTOME\\n\\nCOMPTE\\n\\nRENDU\\n\\n1900.\\n\\nP A R T I E .\\n\\nI.\\n\\nDES\\n\\nSÉANCES,\\n\\nBRUXELLES,\\nIMPRIMERIE VEUVE JULIEN BAEllTSOEN, GRAND'PLACE, 5.\\n1900\\n\\n\\x0c\\x0cN°l.\\n\\nCOMPTE RENDU DE LA SÉANCE DU 8 JANVIER 1900.\\n\\nVILLE DE B R U X E L L E S\\n\\nBULLETIN\\n\\nCOMMUNAL\\n\\nANNÉE\\n\\nCONSEIL\\n\\n1900\\n\\nC O M M U N A L .\\n\\nSéance du 8 Janvier 1 9 0 0 .\\nPrésidence de M . EMILE D E M O T , Bourgmestre.\\n\\nSOMMAIRE :\\n\\n1.\\n2.\\n3.\\n4.\\n5.\\n6.\\n7.\\n7A.\\n8.\\n\\nPrestation de serment et installation \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer le contenu du fichier et constater les \"déchets\"\n",
    "with open(os.path.join(temp_path, f'{DECADE}.txt'), 'r') as f:\n",
    "    before = f.read()\n",
    "\n",
    "before[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c2ce7-48ea-4b5e-a27b-e3c2d6534935",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61258ec4-a4bf-4894-87f8-f694377343cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"les\", \"plus\", \"cette\", \"fait\", \"faire\", \"être\", \"deux\", \"comme\", \"dont\", \"tout\", \n",
    "       \"ils\", \"bien\", \"sans\", \"peut\", \"tous\", \"après\", \"ainsi\", \"donc\", \"cet\", \"sous\",\n",
    "       \"celle\", \"entre\", \"encore\", \"toutes\", \"pendant\", \"moins\", \"dire\", \"cela\", \"non\",\n",
    "       \"faut\", \"trois\", \"aussi\", \"dit\", \"avoir\", \"doit\", \"contre\", \"depuis\", \"autres\",\n",
    "       \"van\", \"het\", \"autre\", \"jusqu\"]\n",
    "sw = set(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf05d1cc-f880-4bd4-8185-b9c1589ad6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 stopwords:\n",
      " ['ai', 'aie', 'aient', 'aies', 'ainsi', 'ait', 'après', 'as', 'au', 'aura', 'aurai', 'auraient', 'aurais', 'aurait', 'auras', 'aurez', 'auriez', 'aurions', 'aurons', 'auront', 'aussi', 'autre', 'autres', 'aux', 'avaient', 'avais', 'avait', 'avec', 'avez', 'aviez', 'avions', 'avoir', 'avons', 'ayant', 'ayante', 'ayantes', 'ayants', 'ayez', 'ayons', 'bien', 'c', 'ce', 'cela', 'celle', 'ces', 'cet', 'cette', 'comme', 'contre', 'd', 'dans', 'de', 'depuis', 'des', 'deux', 'dire', 'dit', 'doit', 'donc', 'dont', 'du', 'elle', 'en', 'encore', 'entre', 'es', 'est', 'et', 'eu', 'eue', 'eues', 'eurent', 'eus', 'eusse', 'eussent', 'eusses', 'eussiez', 'eussions', 'eut', 'eux', 'eûmes', 'eût', 'eûtes', 'faire', 'fait', 'faut', 'furent', 'fus', 'fusse', 'fussent', 'fusses', 'fussiez', 'fussions', 'fut', 'fûmes', 'fût', 'fûtes', 'het', 'il', 'ils', 'j', 'je', 'jusqu', 'l', 'la', 'le', 'les', 'leur', 'lui', 'm', 'ma', 'mais', 'me', 'mes', 'moi', 'moins', 'mon', 'même', 'n', 'ne', 'non', 'nos', 'notre', 'nous', 'on', 'ont', 'ou', 'par', 'pas', 'pendant', 'peut', 'plus', 'pour', 'qu', 'que', 'qui', 's', 'sa', 'sans', 'se', 'sera', 'serai', 'seraient', 'serais', 'serait', 'seras', 'serez', 'seriez', 'serions', 'serons', 'seront', 'ses', 'soient', 'sois', 'soit', 'sommes', 'son', 'sont', 'sous', 'soyez', 'soyons', 'suis', 'sur', 't', 'ta', 'te', 'tes', 'toi', 'ton', 'tous', 'tout', 'toutes', 'trois', 'tu', 'un', 'une', 'van', 'vos', 'votre', 'vous', 'y', 'à', 'étaient', 'étais', 'était', 'étant', 'étante', 'étantes', 'étants', 'étiez', 'étions', 'été', 'étée', 'étées', 'étés', 'êtes', 'être']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(sw)} stopwords:\\n {sorted(sw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad36cb0-9ee5-4aa7-a25c-78af07e2e7ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b05e738c-f8d5-449e-b797-8723ec5915b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(DECADE, folder=None):\n",
    "    if folder is None:\n",
    "        input_path = f\"{DECADE}.txt\"\n",
    "        output_path = f\"{DECADE}_clean.txt\"\n",
    "    else:\n",
    "        input_path = f\"{folder}/{DECADE}.txt\"\n",
    "        output_path = f\"{folder}/{DECADE}_clean.txt\"\n",
    "    output = open(output_path, \"w\", encoding='utf-8')\n",
    "    with open(input_path, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        words = nltk.wordpunct_tokenize(text)\n",
    "        kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "        kept_string = \" \".join(kept)\n",
    "        output.write(kept_string)\n",
    "    return f'Output has been written in {output_path}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ffc05a-089c-4f3f-8870-18371d92324c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output has been written in ../data/tmp/1900_clean.txt!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(DECADE, folder=temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295005b-cae2-447a-bf45-22d1e0a81c99",
   "metadata": {},
   "source": [
    "## Counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "744b2516-e933-4554-a0ef-643cfe4dd51f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0  2166991 18434525 ../data/tmp/1900_clean.txt\n"
     ]
    }
   ],
   "source": [
    "## word's total number 1840\n",
    "!wc ../data/tmp/1900_clean.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a2f01-1a7c-49ad-bc26-6f47b8194728",
   "metadata": {},
   "source": [
    "## Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ed0dac8-837c-4e9e-91e9-7197599b98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du contenu du fichier\n",
    "txt_path = '../data/tmp/1900_clean.txt'\n",
    "limit = 10**8\n",
    "\n",
    "with open(txt_path) as f:\n",
    "    text = f.read()[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "722993c0-ff31-4a2b-862a-0de0e047f096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2166991 words found\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "496d832d-66d4-4fcb-bee3-348b0f8ea348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2166991 words kept (82541 different word forms)\n"
     ]
    }
   ],
   "source": [
    "# Eliminer les stopwords et les termes non alphabétiques\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852149e-d625-4cfd-97b9-9f7f02b718ba",
   "metadata": {},
   "source": [
    "## Finally couting related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27e45009-e520-4705-97fb-e6d9d10b4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = '../data/tmp/1900_clean.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "118824e1-e4f5-42ec-b584-eedd3aab9f09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Le mot 'culture' apparaître 236 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cultures' apparaître 1125 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cultures' apparaître 9 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'théâtres' apparaître 246 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Théâtre' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Théâtres' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cultures' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Museum' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'museums' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Museums' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'musée' apparaître 699 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Musée' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'musées' apparaître 46 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Musées' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'espace culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Espace culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'espaces culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Espace de culture' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'espacee de culture' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'lieu culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Lieu culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'lieux culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Lieux culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'endroit culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'endroits culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'centre culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Centre culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'centres culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Centres culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cinéma' apparaître 13 fois dans le corpus\n",
      "\n",
      "\n",
      " 'patrimoine culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Patrimoine culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cinémas' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Cinéma' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Cinémas' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Cinema' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cinema' apparaître 0 fois dans le corpus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = 'culture'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_culture = f.read().count(word)\n",
    "print(f\"\\n Le mot 'culture' apparaître {occurrence_culture} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'théâtre'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_théâtre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cultures' apparaître {occurrence_théâtre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'theatre'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_theatre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cultures' apparaître {occurrence_theatre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'théâtres'\n",
    "with open(txt_path) as f:\n",
    "    occurrence__theatres = f.read().count(word)\n",
    "print(f\"\\n Le mot 'théâtres' apparaître {occurrence__theatres} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Théâtre'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_theatre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Théâtre' apparaître {occurrence_theatre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Théâtres'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_theatre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Théâtres' apparaître {occurrence_theatre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'museum'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museum = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cultures' apparaître {occurrence_museum} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Museum'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museum = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Museum' apparaître {occurrence_museum} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'museums'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museums = f.read().count(word)\n",
    "print(f\"\\n Le mot 'museums' apparaître {occurrence_museums} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Museums'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museums = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Museums' apparaître {occurrence_museums} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'musée'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musée = f.read().count(word)\n",
    "print(f\"\\n Le mot 'musée' apparaître {occurrence_musée} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'Musée'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musée = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Musée' apparaître {occurrence_musée} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'musées'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musées = f.read().count(word)\n",
    "print(f\"\\n Le mot 'musées' apparaître {occurrence_musées} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'Musées'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musées = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Musées' apparaître {occurrence_musées} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'espace culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_ec = f.read().count(word)\n",
    "print(f\"\\n 'espace culturel' apparaître {occurrence_ec} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Espace culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_ec = f.read().count(word)\n",
    "print(f\"\\n 'Espace culturel' apparaître {occurrence_ec} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'espaces culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_ecs = f.read().count(word)\n",
    "print(f\"\\n 'espaces culturels' apparaître {occurrence_ecs} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'espace de culture'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_edc = f.read().count(word)\n",
    "print(f\"\\n 'Espace de culture' apparaître {occurrence_edc} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'espaces de culture'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_esdc = f.read().count(word)\n",
    "print(f\"\\n 'espacee de culture' apparaître {occurrence_esdc} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'lieu culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieu = f.read().count(word)\n",
    "print(f\"\\n 'lieu culturel' apparaître {occurrence_lieu} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Lieu culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieu = f.read().count(word)\n",
    "print(f\"\\n 'Lieu culturel' apparaître {occurrence_lieu} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'lieux culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieux = f.read().count(word)\n",
    "print(f\"\\n 'lieux culturels' apparaître {occurrence_lieux} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Lieux culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieux = f.read().count(word)\n",
    "print(f\"\\n 'Lieux culturels' apparaître {occurrence_lieux} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'endroit culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_endcult = f.read().count(word)\n",
    "print(f\"\\n 'endroit culturel' apparaître {occurrence_endcult} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'endroits culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_endcults = f.read().count(word)\n",
    "print(f\"\\n 'endroits culturels' apparaître {occurrence_endcults} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'centre culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centre_culturel = f.read().count(word)\n",
    "print(f\"\\n 'centre culturel' apparaître {occurrence_centre_culturel} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Centre culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centre_culturel = f.read().count(word)\n",
    "print(f\"\\n 'Centre culturel' apparaître {occurrence_centre_culturel} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'centres culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centres_culturels = f.read().count(word)\n",
    "print(f\"\\n 'centres culturels' apparaître {occurrence_centres_culturels} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Centres culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centres_culturels = f.read().count(word)\n",
    "print(f\"\\n 'Centres culturels' apparaître {occurrence_centres_culturels} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'cinéma'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinema = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cinéma' apparaître {occurrence_cinema} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'patrimoine culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_patrimoine = f.read().count(word)\n",
    "print(f\"\\n 'patrimoine culturel' apparaître {occurrence_patrimoine} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Patrimoine culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_patrimoinec = f.read().count(word)\n",
    "print(f\"\\n 'Patrimoine culturel' apparaître {occurrence_patrimoinec} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'cinémas'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinema = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cinémas' apparaître {occurrence_cinema} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Cinéma'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinemaC = f.read().count(word)\n",
    "print(f\"\\n 'Cinéma' apparaître {occurrence_cinemaC} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Cinémas'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinemaCs = f.read().count(word)\n",
    "print(f\"\\n 'Cinémas' apparaître {occurrence_cinemaCs} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Cinema'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_avencine = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Cinema' apparaître {occurrence_avencine } fois dans le corpus\\n\")\n",
    "\n",
    "word = 'cinema'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_avencine = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cinema' apparaître {occurrence_avencine } fois dans le corpus\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b829b0-0fe2-4f12-bdec-c87c57d1161f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vérifier les 100 mots les plus fréquents  - liée au sujet recherché ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed1c7e6-b5fd-47f6-893d-7c6e7a5b0d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bourgmestre',\n",
       " 'Bruxelles',\n",
       " 'Collège',\n",
       " 'Conseil',\n",
       " 'D E S BIENS',\n",
       " 'Den Nest',\n",
       " 'DÉSIGNATION D E S BIENS',\n",
       " 'Messieurs',\n",
       " 'Remerciements',\n",
       " 'VILLE',\n",
       " 'art',\n",
       " 'avons',\n",
       " 'boni recette dépense',\n",
       " 'bourgmestre',\n",
       " 'bruxelles',\n",
       " \"c'est\",\n",
       " 'chapitre',\n",
       " 'collège',\n",
       " 'commune',\n",
       " 'conseil',\n",
       " 'conseil communal',\n",
       " 'conseil général',\n",
       " 'c’est',\n",
       " \"d'un\",\n",
       " \"d'une\",\n",
       " 'den Nest',\n",
       " 'depenses dépenses recettes',\n",
       " 'dit',\n",
       " 'déficit recette dépense',\n",
       " 'dépense',\n",
       " 'dépense recette boni',\n",
       " 'dépenses',\n",
       " 'dépenses dépenses',\n",
       " 'dépenses dépenses prévues',\n",
       " \"dépenses ordinaires qu'on\",\n",
       " 'd’une',\n",
       " 'francs',\n",
       " 'général',\n",
       " \"l'article\",\n",
       " 'mais',\n",
       " 'messieurs',\n",
       " 'n’est',\n",
       " 'ordinaires',\n",
       " 'p r é',\n",
       " 'prix',\n",
       " \"q u ' i\",\n",
       " 'q u e',\n",
       " 'q u i',\n",
       " 'q u é',\n",
       " \"qu'on\",\n",
       " 'question',\n",
       " 'qu’il',\n",
       " 'recette dépense',\n",
       " 'recette dépense prévue',\n",
       " 'recettes imprévues. dépenses',\n",
       " 'recettes recettes',\n",
       " 'rue',\n",
       " 'sacrés ordinaires',\n",
       " 'services',\n",
       " 'titres',\n",
       " 'total',\n",
       " 'vases sacrés ordinaires',\n",
       " 'ville',\n",
       " 'vue',\n",
       " 'é d i t',\n",
       " 'é p a r',\n",
       " 'é t r ',\n",
       " 'é t é',\n",
       " 'ê t r',\n",
       " 'œ u v r e'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création d'une liste de mots à ignorer\n",
    "ignored = set([\"Collège\", \"collège\", \"francs\", \"Bourgmestre\",\"Messieurs\",\"VILLE\", \"Conseil\", \"conseil communal\", \n",
    "               \"conseil général\", \"conseil\", \"conseil communal\", \"général\", \"d'un\",\"d'une\", \"c'est\", \"ordinaires\", \n",
    "               \"chapitre\", \"titres\", \"recette dépense\", \"services\", \"dépenses\", \"dépense\", \"dépenses dépenses prévues\", \n",
    "               \"déficit recette dépense\", \"recette dépense prévue\", \"boni recette dépense\", \"dépense recette boni\", \n",
    "               \"recettes recettes\", \"dépenses dépenses\", \"qu'on\", \"depenses dépenses recettes\", \n",
    "               \"vases sacrés ordinaires\", \"sacrés ordinaires\", \"dépenses ordinaires qu'on\", \n",
    "               \"depenses dépenses recettes\", \"recettes imprévues. dépenses\", \"dit\", \"vue\", \"n’est\", \"avons\", \n",
    "               \"d’une\",\"rue\", \"Den Nest\", \"commune\", \"qu’il\", \"question\", \"ville\", \"c’est\", \"mais\", \"den Nest\", \n",
    "               \"total\", \"art\", \"l'article\", \"Bourgmestre\", \"bourgmestre\", \"Messieurs\", \"VILLE\", \"prix\", \"Bruxelles\",\n",
    "               \"bruxelles\", \"messieurs\", \"é p a r\", \"é d i t\", \"p r é\", \"q u é\", \"é t é\", \"q u i\", \"q u ' i\", \"ê t r\", \n",
    "               \"œ u v r e\", \"D E S BIENS\", \"Remerciements\", \"q u e\",\"DÉSIGNATION D E S BIENS\", \"é t r \"])\n",
    "ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a99fb623-cb80-4a3a-9891-31914e666b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019048 words kept (82520 different word forms)\n"
     ]
    }
   ],
   "source": [
    "# Eliminer les stopwords et les termes non alphabétiques\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw and w not in ignored]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffc90bf2-f890-48e1-abb2-97ee4312b900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('service', 8781),\n",
       " ('frais', 8192),\n",
       " ('travaux', 6843),\n",
       " ('recettes', 6093),\n",
       " ('budget', 5935),\n",
       " ('heures', 5745),\n",
       " ('communal', 5709),\n",
       " ('école', 5686),\n",
       " ('cours', 5481),\n",
       " ('etc', 5390),\n",
       " ('section', 5367),\n",
       " ('compte', 5362),\n",
       " ('entretien', 5314),\n",
       " ('avis', 5255),\n",
       " ('saint', 5052),\n",
       " ('place', 4768),\n",
       " ('administration', 4748),\n",
       " ('hospices', 4484),\n",
       " ('echevin', 4381),\n",
       " ('ans', 4343),\n",
       " ('enfants', 4144),\n",
       " ('somme', 4104),\n",
       " ('société', 3985),\n",
       " ('décembre', 3959),\n",
       " ('publique', 3927),\n",
       " ('année', 3821),\n",
       " ('demande', 3806),\n",
       " ('personnel', 3758),\n",
       " ('rapport', 3748),\n",
       " ('église', 3699),\n",
       " ('ouvriers', 3674),\n",
       " ('exercice', 3582),\n",
       " ('lieu', 3452),\n",
       " ('traitement', 3401),\n",
       " ('partie', 3372),\n",
       " ('nombre', 3363),\n",
       " ('police', 3357),\n",
       " ('leurs', 3353),\n",
       " ('adjudication', 3306),\n",
       " ('droit', 3276),\n",
       " ('divers', 3272),\n",
       " ('favorable', 3128),\n",
       " ('maison', 3033),\n",
       " ('bureau', 3025),\n",
       " ('proposition', 3006),\n",
       " ('écoles', 3000),\n",
       " ('charges', 2992),\n",
       " ('part', 2976),\n",
       " ('diverses', 2939),\n",
       " ('vente', 2895),\n",
       " ('crédit', 2855),\n",
       " ('séance', 2845),\n",
       " ('jour', 2812),\n",
       " ('honneur', 2782),\n",
       " ('intérêts', 2769),\n",
       " ('fonds', 2763),\n",
       " ('juillet', 2738),\n",
       " ('ordre', 2729),\n",
       " ('situation', 2712),\n",
       " ('voir', 2709),\n",
       " ('membres', 2695),\n",
       " ('cas', 2680),\n",
       " ('terrain', 2680),\n",
       " ('subside', 2676),\n",
       " ('communale', 2611),\n",
       " ('loi', 2610),\n",
       " ('avant', 2600),\n",
       " ('janvier', 2598),\n",
       " ('extraordinaires', 2545),\n",
       " ('gaz', 2532),\n",
       " ('octobre', 2528),\n",
       " ('ceux', 2515),\n",
       " ('etat', 2510),\n",
       " ('eau', 2498),\n",
       " ('produit', 2481),\n",
       " ('mois', 2466),\n",
       " ('cahier', 2453),\n",
       " ('secours', 2424),\n",
       " ('ecole', 2422),\n",
       " ('élèves', 2373),\n",
       " ('elles', 2369),\n",
       " ('conditions', 2354),\n",
       " ('état', 2339),\n",
       " ('mars', 2331),\n",
       " ('legs', 2326),\n",
       " ('travail', 2267),\n",
       " ('caisse', 2258),\n",
       " ('hôtel', 2250),\n",
       " ('construction', 2230),\n",
       " ('approbation', 2229),\n",
       " ('nature', 2215),\n",
       " ('classe', 2215),\n",
       " ('grand', 2210),\n",
       " ('quatre', 2181),\n",
       " ('jours', 2159),\n",
       " ('maisons', 2159),\n",
       " ('proposer', 2157),\n",
       " ('montant', 2151),\n",
       " ('terrains', 2150),\n",
       " ('suite', 2144)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f12fe5-daeb-4cc5-96ea-e2fe9f30909d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194cce5-8775-4f61-a1d6-ec1f458aee9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
