{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7612caae-bf4a-4bae-8f4b-957bcba9a004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yake\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yake\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image\n",
    "\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "\n",
    "import sys\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import sys\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d65367f4-551a-4218-946f-1737c249716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "675dfa06-e1e6-4e87-8a7a-6b0446b8283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f8136021-9927-40cb-b2f4-31d86aa9abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/txt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a0981312-3c7a-4fcc-b0a5-d3d3c8cdfd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0c8d2-1335-4ebf-98a3-279189209f7a",
   "metadata": {},
   "source": [
    "## Choisir une décennie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "a75160d0-4635-4865-86eb-b62d9ba1d1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DECADE = '1840'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1dd8e-d5e6-4bf0-9248-92b073965e09",
   "metadata": {},
   "source": [
    "## Charger tous les  fichiers de la décennie et en créer une liste de textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1b8c1184-1276-418d-92c8-ca9cc985464c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bxl_1847_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1847_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1847_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1847_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1847_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1848_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1848_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1848_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1849_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1849_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1849_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1849_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1849_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1849_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1849_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1849_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1849_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1849_Tome_II1_Part_5.txt',\n",
       " 'Bxl_1849_Tome_II1_Part_6.txt',\n",
       " 'Bxl_1849_Tome_II1_Part_7.txt']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_path = \"../data/txt/\"\n",
    "\n",
    "#files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "#print(files)\n",
    "\n",
    "# Lister les fichiers de cette année\n",
    "data_path = '../data'\n",
    "txt_path = '../data/txt'\n",
    "txts = [f for f in os.listdir(txt_path) if os.path.isfile(os.path.join(txt_path, f)) and f\"_{DECADE[:-1]}\" in f]\n",
    "txts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "deb16ee1-2472-4c9a-a0c6-d8107f59c90d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d0c3b018-a348-428f-90d5-b024aa1df739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stocker le contenu de ces fichiers dans une liste\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(os.path.join(txt_path, txt), 'r') as f:\n",
    "        content_list.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "c6a867c8-48b8-4bc4-8abf-c9e423bc2c28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bxl_1847_Tome_I1_Part_1.txt'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer les 200 premiers caractères du contenu du premier fichier\n",
    "txts[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "2b5b2f9c-19b2-4021-9517-4ec25de6dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrire tout le contenu dans un fichier temporaire\n",
    "temp_path = '../data/tmp'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "with open(os.path.join(temp_path, f'{DECADE}.txt'), 'w') as f:\n",
    "    f.write(' '.join(content_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "dec4332b-16c0-4c7d-b404-cca6e7910bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textract\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "544e06fd-758a-4cad-84e7-ed292a9e7aca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" B Les bâtimens appartenant à l'Etat, qui sont employés pour des casernes\\nou des écuries militaires, seront cédés à cet effet aux administrations locales,\\nà charge de les entretenir cri bon étal et d e ne les employer à aucun autre\\nusage que celui dont il vient d'être parlé. »\\nSons disons que le législateur de 1814 n'a fait que suivre l'esprit du déeret de 1810. Que voulait ce décret? Que les villes fournissent le logement\\naux troupes, mais uniquement dans les casernes cédées à cet effet; o r , \""
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer le contenu du fichier et constater les \"déchets\"\n",
    "with open(os.path.join(temp_path, f'{DECADE}.txt'), 'r') as f:\n",
    "    before = f.read()\n",
    "\n",
    "before[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106e7d1-6e02-41b7-bd6b-0f3c892ad5bd",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "af4de2e1-fabb-49fb-ac04-119552bade34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"les\", \"plus\", \"cette\", \"fait\", \"faire\", \"être\", \"deux\", \"comme\", \"dont\", \"tout\", \n",
    "       \"ils\", \"bien\", \"sans\", \"peut\", \"tous\", \"après\", \"ainsi\", \"donc\", \"cet\", \"sous\",\n",
    "       \"celle\", \"entre\", \"encore\", \"toutes\", \"pendant\", \"moins\", \"dire\", \"cela\", \"non\",\n",
    "       \"faut\", \"trois\", \"aussi\", \"dit\", \"avoir\", \"doit\", \"contre\", \"depuis\", \"autres\",\n",
    "       \"van\", \"het\", \"autre\", \"jusqu\"]\n",
    "sw = set(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "668605f5-393b-4a56-8958-9f7dd45a3053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 stopwords:\n",
      " ['ai', 'aie', 'aient', 'aies', 'ainsi', 'ait', 'après', 'as', 'au', 'aura', 'aurai', 'auraient', 'aurais', 'aurait', 'auras', 'aurez', 'auriez', 'aurions', 'aurons', 'auront', 'aussi', 'autre', 'autres', 'aux', 'avaient', 'avais', 'avait', 'avec', 'avez', 'aviez', 'avions', 'avoir', 'avons', 'ayant', 'ayante', 'ayantes', 'ayants', 'ayez', 'ayons', 'bien', 'c', 'ce', 'cela', 'celle', 'ces', 'cet', 'cette', 'comme', 'contre', 'd', 'dans', 'de', 'depuis', 'des', 'deux', 'dire', 'dit', 'doit', 'donc', 'dont', 'du', 'elle', 'en', 'encore', 'entre', 'es', 'est', 'et', 'eu', 'eue', 'eues', 'eurent', 'eus', 'eusse', 'eussent', 'eusses', 'eussiez', 'eussions', 'eut', 'eux', 'eûmes', 'eût', 'eûtes', 'faire', 'fait', 'faut', 'furent', 'fus', 'fusse', 'fussent', 'fusses', 'fussiez', 'fussions', 'fut', 'fûmes', 'fût', 'fûtes', 'het', 'il', 'ils', 'j', 'je', 'jusqu', 'l', 'la', 'le', 'les', 'leur', 'lui', 'm', 'ma', 'mais', 'me', 'mes', 'moi', 'moins', 'mon', 'même', 'n', 'ne', 'non', 'nos', 'notre', 'nous', 'on', 'ont', 'ou', 'par', 'pas', 'pendant', 'peut', 'plus', 'pour', 'qu', 'que', 'qui', 's', 'sa', 'sans', 'se', 'sera', 'serai', 'seraient', 'serais', 'serait', 'seras', 'serez', 'seriez', 'serions', 'serons', 'seront', 'ses', 'soient', 'sois', 'soit', 'sommes', 'son', 'sont', 'sous', 'soyez', 'soyons', 'suis', 'sur', 't', 'ta', 'te', 'tes', 'toi', 'ton', 'tous', 'tout', 'toutes', 'trois', 'tu', 'un', 'une', 'van', 'vos', 'votre', 'vous', 'y', 'à', 'étaient', 'étais', 'était', 'étant', 'étante', 'étantes', 'étants', 'étiez', 'étions', 'été', 'étée', 'étées', 'étés', 'êtes', 'être']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(sw)} stopwords:\\n {sorted(sw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad36cb0-9ee5-4aa7-a25c-78af07e2e7ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "b05e738c-f8d5-449e-b797-8723ec5915b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(DECADE, folder=None):\n",
    "    if folder is None:\n",
    "        input_path = f\"{DECADE}.txt\"\n",
    "        output_path = f\"{DECADE}_clean.txt\"\n",
    "    else:\n",
    "        input_path = f\"{folder}/{DECADE}.txt\"\n",
    "        output_path = f\"{folder}/{DECADE}_clean.txt\"\n",
    "    output = open(output_path, \"w\", encoding='utf-8')\n",
    "    with open(input_path, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        words = nltk.wordpunct_tokenize(text)\n",
    "        kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "        kept_string = \" \".join(kept)\n",
    "        output.write(kept_string)\n",
    "    return f'Output has been written in {output_path}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "15ffc05a-089c-4f3f-8870-18371d92324c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output has been written in ../data/tmp/1840_clean.txt!'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(DECADE, folder=temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295005b-cae2-447a-bf45-22d1e0a81c99",
   "metadata": {},
   "source": [
    "## Counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "744b2516-e933-4554-a0ef-643cfe4dd51f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  270233 2298260 ../data/tmp/1840_clean.txt\n"
     ]
    }
   ],
   "source": [
    "## word's total number 1840\n",
    "!wc ../data/tmp/1840_clean.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961e168-bd76-415b-bfb6-c3612075b255",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c08399bc-aefb-4b21-9c0a-cd61b442c23e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"les\", \"plus\", \"cette\", \"fait\", \"faire\", \"être\", \"deux\", \"comme\", \"dont\", \"tout\", \n",
    "       \"ils\", \"bien\", \"sans\", \"peut\", \"tous\", \"après\", \"ainsi\", \"donc\", \"cet\", \"sous\",\n",
    "       \"celle\", \"entre\", \"encore\", \"toutes\", \"pendant\", \"moins\", \"dire\", \"cela\", \"non\",\n",
    "       \"faut\", \"trois\", \"aussi\", \"dit\", \"avoir\", \"doit\", \"contre\", \"depuis\", \"autres\",\n",
    "       \"van\", \"het\", \"autre\", \"jusqu\"]\n",
    "sw = set(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1c0766b1-16f5-4739-81c1-761a6e4d813c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 stopwords:\n",
      " ['ai', 'aie', 'aient', 'aies', 'ainsi', 'ait', 'après', 'as', 'au', 'aura', 'aurai', 'auraient', 'aurais', 'aurait', 'auras', 'aurez', 'auriez', 'aurions', 'aurons', 'auront', 'aussi', 'autre', 'autres', 'aux', 'avaient', 'avais', 'avait', 'avec', 'avez', 'aviez', 'avions', 'avoir', 'avons', 'ayant', 'ayante', 'ayantes', 'ayants', 'ayez', 'ayons', 'bien', 'c', 'ce', 'cela', 'celle', 'ces', 'cet', 'cette', 'comme', 'contre', 'd', 'dans', 'de', 'depuis', 'des', 'deux', 'dire', 'dit', 'doit', 'donc', 'dont', 'du', 'elle', 'en', 'encore', 'entre', 'es', 'est', 'et', 'eu', 'eue', 'eues', 'eurent', 'eus', 'eusse', 'eussent', 'eusses', 'eussiez', 'eussions', 'eut', 'eux', 'eûmes', 'eût', 'eûtes', 'faire', 'fait', 'faut', 'furent', 'fus', 'fusse', 'fussent', 'fusses', 'fussiez', 'fussions', 'fut', 'fûmes', 'fût', 'fûtes', 'het', 'il', 'ils', 'j', 'je', 'jusqu', 'l', 'la', 'le', 'les', 'leur', 'lui', 'm', 'ma', 'mais', 'me', 'mes', 'moi', 'moins', 'mon', 'même', 'n', 'ne', 'non', 'nos', 'notre', 'nous', 'on', 'ont', 'ou', 'par', 'pas', 'pendant', 'peut', 'plus', 'pour', 'qu', 'que', 'qui', 's', 'sa', 'sans', 'se', 'sera', 'serai', 'seraient', 'serais', 'serait', 'seras', 'serez', 'seriez', 'serions', 'serons', 'seront', 'ses', 'soient', 'sois', 'soit', 'sommes', 'son', 'sont', 'sous', 'soyez', 'soyons', 'suis', 'sur', 't', 'ta', 'te', 'tes', 'toi', 'ton', 'tous', 'tout', 'toutes', 'trois', 'tu', 'un', 'une', 'van', 'vos', 'votre', 'vous', 'y', 'à', 'étaient', 'étais', 'était', 'étant', 'étante', 'étantes', 'étants', 'étiez', 'étions', 'été', 'étée', 'étées', 'étés', 'êtes', 'être']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(sw)} stopwords:\\n {sorted(sw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a2f01-1a7c-49ad-bc26-6f47b8194728",
   "metadata": {},
   "source": [
    "## Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "3ed0dac8-837c-4e9e-91e9-7197599b98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du contenu du fichier\n",
    "txt_path = '../data/tmp/1840_clean.txt'\n",
    "limit = 10**8\n",
    "\n",
    "with open(txt_path) as f:\n",
    "    text = f.read()[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "722993c0-ff31-4a2b-862a-0de0e047f096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270233 words found\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "496d832d-66d4-4fcb-bee3-348b0f8ea348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270233 words kept (25783 different word forms)\n"
     ]
    }
   ],
   "source": [
    "# Eliminer les stopwords et les termes non alphabétiques\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852149e-d625-4cfd-97b9-9f7f02b718ba",
   "metadata": {},
   "source": [
    "## Finally couting related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "27e45009-e520-4705-97fb-e6d9d10b4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = '../data/tmp/1840_clean.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "118824e1-e4f5-42ec-b584-eedd3aab9f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Le mot 'culture' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cultures' apparaître 284 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cultures' apparaître 1 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'théâtres' apparaître 100 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Théâtre' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Théâtres' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cultures' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Museum' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'museums' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Museums' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'musée' apparaître 23 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Musée' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'musées' apparaître 1 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Musées' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'espace culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Espace culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'espaces culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Espace de culture' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'espacee de culture' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'lieu culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Lieu culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'lieux culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Lieux culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'endroit culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'endroits culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'centre culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Centre culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'centres culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Centres culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cinéma' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'patrimoine culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Patrimoine culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cinémas' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Cinéma' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Cinémas' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Cinema' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cinema' apparaître 0 fois dans le corpus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(txt_path) as f:\n",
    "    occurrence_culture = f.read().count(word)\n",
    "print(f\"\\n Le mot 'culture' apparaître {occurrence_culture} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'théâtre'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_théâtre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cultures' apparaître {occurrence_théâtre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'theatre'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_theatre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cultures' apparaître {occurrence_theatre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'théâtres'\n",
    "with open(txt_path) as f:\n",
    "    occurrence__theatres = f.read().count(word)\n",
    "print(f\"\\n Le mot 'théâtres' apparaître {occurrence__theatres} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Théâtre'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_theatre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Théâtre' apparaître {occurrence_theatre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Théâtres'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_theatre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Théâtres' apparaître {occurrence_theatre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'museum'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museum = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cultures' apparaître {occurrence_museum} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Museum'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museum = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Museum' apparaître {occurrence_museum} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'museums'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museums = f.read().count(word)\n",
    "print(f\"\\n Le mot 'museums' apparaître {occurrence_museums} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Museums'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museums = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Museums' apparaître {occurrence_museums} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'musée'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musée = f.read().count(word)\n",
    "print(f\"\\n Le mot 'musée' apparaître {occurrence_musée} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'Musée'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musée = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Musée' apparaître {occurrence_musée} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'musées'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musées = f.read().count(word)\n",
    "print(f\"\\n Le mot 'musées' apparaître {occurrence_musées} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'Musées'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musées = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Musées' apparaître {occurrence_musées} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'espace culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_ec = f.read().count(word)\n",
    "print(f\"\\n 'espace culturel' apparaître {occurrence_ec} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Espace culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_ec = f.read().count(word)\n",
    "print(f\"\\n 'Espace culturel' apparaître {occurrence_ec} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'espaces culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_ecs = f.read().count(word)\n",
    "print(f\"\\n 'espaces culturels' apparaître {occurrence_ecs} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'espace de culture'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_edc = f.read().count(word)\n",
    "print(f\"\\n 'Espace de culture' apparaître {occurrence_edc} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'espaces de culture'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_esdc = f.read().count(word)\n",
    "print(f\"\\n 'espacee de culture' apparaître {occurrence_esdc} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'lieu culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieu = f.read().count(word)\n",
    "print(f\"\\n 'lieu culturel' apparaître {occurrence_lieu} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Lieu culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieu = f.read().count(word)\n",
    "print(f\"\\n 'Lieu culturel' apparaître {occurrence_lieu} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'lieux culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieux = f.read().count(word)\n",
    "print(f\"\\n 'lieux culturels' apparaître {occurrence_lieux} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Lieux culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieux = f.read().count(word)\n",
    "print(f\"\\n 'Lieux culturels' apparaître {occurrence_lieux} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'endroit culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_endcult = f.read().count(word)\n",
    "print(f\"\\n 'endroit culturel' apparaître {occurrence_endcult} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'endroits culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_endcults = f.read().count(word)\n",
    "print(f\"\\n 'endroits culturels' apparaître {occurrence_endcults} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'centre culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centre_culturel = f.read().count(word)\n",
    "print(f\"\\n 'centre culturel' apparaître {occurrence_centre_culturel} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Centre culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centre_culturel = f.read().count(word)\n",
    "print(f\"\\n 'Centre culturel' apparaître {occurrence_centre_culturel} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'centres culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centres_culturels = f.read().count(word)\n",
    "print(f\"\\n 'centres culturels' apparaître {occurrence_centres_culturels} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Centres culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centres_culturels = f.read().count(word)\n",
    "print(f\"\\n 'Centres culturels' apparaître {occurrence_centres_culturels} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'cinéma'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinema = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cinéma' apparaître {occurrence_cinema} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'patrimoine culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_patrimoine = f.read().count(word)\n",
    "print(f\"\\n 'patrimoine culturel' apparaître {occurrence_patrimoine} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Patrimoine culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_patrimoinec = f.read().count(word)\n",
    "print(f\"\\n 'Patrimoine culturel' apparaître {occurrence_patrimoinec} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'cinémas'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinema = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cinémas' apparaître {occurrence_cinema} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Cinéma'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinemaC = f.read().count(word)\n",
    "print(f\"\\n 'Cinéma' apparaître {occurrence_cinemaC} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Cinémas'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinemaCs = f.read().count(word)\n",
    "print(f\"\\n 'Cinémas' apparaître {occurrence_cinemaCs} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Cinema'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_avencine = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Cinema' apparaître {occurrence_avencine } fois dans le corpus\\n\")\n",
    "\n",
    "word = 'cinema'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_avencine = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cinema' apparaître {occurrence_avencine } fois dans le corpus\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b829b0-0fe2-4f12-bdec-c87c57d1161f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vérifier les 100 mots les plus fréquents  - liée au sujet recherché ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f5b38ead-6bc8-4a20-b153-e6d7376451b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bourgmestre',\n",
       " 'Bruxelles',\n",
       " 'Collège',\n",
       " 'Conseil',\n",
       " 'D E S BIENS',\n",
       " 'Den Nest',\n",
       " 'DÉSIGNATION D E S BIENS',\n",
       " 'Messieurs',\n",
       " 'Remerciements',\n",
       " 'VILLE',\n",
       " 'art',\n",
       " 'avons',\n",
       " 'boni recette dépense',\n",
       " 'bourgmestre',\n",
       " 'bruxelles',\n",
       " \"c'est\",\n",
       " 'chapitre',\n",
       " 'collège',\n",
       " 'commune',\n",
       " 'conseil',\n",
       " 'conseil communal',\n",
       " 'conseil général',\n",
       " 'c’est',\n",
       " \"d'un\",\n",
       " \"d'une\",\n",
       " 'den Nest',\n",
       " 'depenses dépenses recettes',\n",
       " 'dit',\n",
       " 'déficit recette dépense',\n",
       " 'dépense',\n",
       " 'dépense recette boni',\n",
       " 'dépenses',\n",
       " 'dépenses dépenses',\n",
       " 'dépenses dépenses prévues',\n",
       " \"dépenses ordinaires qu'on\",\n",
       " 'd’une',\n",
       " 'francs',\n",
       " 'général',\n",
       " \"l'article\",\n",
       " 'mais',\n",
       " 'messieurs',\n",
       " 'n’est',\n",
       " 'ordinaires',\n",
       " 'p r é',\n",
       " 'prix',\n",
       " \"q u ' i\",\n",
       " 'q u e',\n",
       " 'q u i',\n",
       " 'q u é',\n",
       " \"qu'on\",\n",
       " 'question',\n",
       " 'qu’il',\n",
       " 'recette dépense',\n",
       " 'recette dépense prévue',\n",
       " 'recettes imprévues. dépenses',\n",
       " 'recettes recettes',\n",
       " 'rue',\n",
       " 'sacrés ordinaires',\n",
       " 'services',\n",
       " 'titres',\n",
       " 'total',\n",
       " 'vases sacrés ordinaires',\n",
       " 'ville',\n",
       " 'vue',\n",
       " 'é d i t',\n",
       " 'é p a r',\n",
       " 'é t r ',\n",
       " 'é t é',\n",
       " 'ê t r',\n",
       " 'œ u v r e'}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création d'une liste de mots à ignorer\n",
    "ignored = set([\"Collège\", \"collège\", \"francs\", \"Bourgmestre\",\"Messieurs\",\"VILLE\", \"Conseil\", \"conseil communal\", \n",
    "               \"conseil général\", \"conseil\", \"conseil communal\", \"général\", \"d'un\",\"d'une\", \"c'est\", \"ordinaires\", \n",
    "               \"chapitre\", \"titres\", \"recette dépense\", \"services\", \"dépenses\", \"dépense\", \"dépenses dépenses prévues\", \n",
    "               \"déficit recette dépense\", \"recette dépense prévue\", \"boni recette dépense\", \"dépense recette boni\", \n",
    "               \"recettes recettes\", \"dépenses dépenses\", \"qu'on\", \"depenses dépenses recettes\", \n",
    "               \"vases sacrés ordinaires\", \"sacrés ordinaires\", \"dépenses ordinaires qu'on\", \n",
    "               \"depenses dépenses recettes\", \"recettes imprévues. dépenses\", \"dit\", \"vue\", \"n’est\", \"avons\", \n",
    "               \"d’une\",\"rue\", \"Den Nest\", \"commune\", \"qu’il\", \"question\", \"ville\", \"c’est\", \"mais\", \"den Nest\", \n",
    "               \"total\", \"art\", \"l'article\", \"Bourgmestre\", \"bourgmestre\", \"Messieurs\", \"VILLE\", \"prix\", \"Bruxelles\",\n",
    "               \"bruxelles\", \"messieurs\", \"é p a r\", \"é d i t\", \"p r é\", \"q u é\", \"é t é\", \"q u i\", \"q u ' i\", \"ê t r\", \n",
    "               \"œ u v r e\", \"D E S BIENS\", \"Remerciements\", \"q u e\",\"DÉSIGNATION D E S BIENS\", \"é t r \"])\n",
    "ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "d9d719e4-247a-49e1-a835-2ae9eac26ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256320 words kept (25762 different word forms)\n"
     ]
    }
   ],
   "source": [
    "# Eliminer les stopwords et les termes non alphabétiques\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw and w not in ignored]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "ffc90bf2-f890-48e1-abb2-97ee4312b900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('section', 1472),\n",
       " ('marché', 988),\n",
       " ('place', 907),\n",
       " ('rapport', 906),\n",
       " ('administration', 878),\n",
       " ('travaux', 796),\n",
       " ('hospices', 690),\n",
       " ('séance', 645),\n",
       " ('budget', 635),\n",
       " ('police', 630),\n",
       " ('partie', 624),\n",
       " ('proposition', 618),\n",
       " ('frais', 573),\n",
       " ('lieu', 568),\n",
       " ('projet', 535),\n",
       " ('demande', 520),\n",
       " ('communal', 518),\n",
       " ('finances', 515),\n",
       " ('somme', 503),\n",
       " ('arrêté', 500),\n",
       " ('droit', 495),\n",
       " ('mois', 494),\n",
       " ('loi', 492),\n",
       " ('ceux', 486),\n",
       " ('heures', 483),\n",
       " ('mètres', 481),\n",
       " ('toute', 478),\n",
       " ('année', 472),\n",
       " ('gouvernement', 470),\n",
       " ('leurs', 467),\n",
       " ('règlement', 457),\n",
       " ('grand', 452),\n",
       " ('cas', 450),\n",
       " ('porte', 443),\n",
       " ('honorable', 442),\n",
       " ('celui', 439),\n",
       " ('communale', 438),\n",
       " ('vente', 436),\n",
       " ('plan', 431),\n",
       " ('nombre', 430),\n",
       " ('subside', 424),\n",
       " ('elles', 415),\n",
       " ('point', 412),\n",
       " ('publique', 408),\n",
       " ('royale', 404),\n",
       " ('parce', 394),\n",
       " ('discussion', 393),\n",
       " ('fonds', 393),\n",
       " ('service', 390),\n",
       " ('construction', 387),\n",
       " ('établissement', 379),\n",
       " ('avant', 373),\n",
       " ('exécution', 366),\n",
       " ('adopté', 364),\n",
       " ('eau', 362),\n",
       " ('compte', 360),\n",
       " ('hommes', 357),\n",
       " ('donner', 356),\n",
       " ('bas', 356),\n",
       " ('publics', 350),\n",
       " ('brouckere', 346),\n",
       " ('article', 341),\n",
       " ('peu', 338),\n",
       " ('commission', 336),\n",
       " ('grande', 335),\n",
       " ('intérêt', 331),\n",
       " ('pourrait', 331),\n",
       " ('temps', 328),\n",
       " ('jour', 328),\n",
       " ('intérêts', 328),\n",
       " ('état', 323),\n",
       " ('hui', 323),\n",
       " ('car', 322),\n",
       " ('autorisation', 320),\n",
       " ('quelques', 319),\n",
       " ('aujourd', 317),\n",
       " ('part', 317),\n",
       " ('établir', 313),\n",
       " ('conclusions', 312),\n",
       " ('effet', 306),\n",
       " ('rues', 305),\n",
       " ('plusieurs', 304),\n",
       " ('seulement', 304),\n",
       " ('fois', 302),\n",
       " ('quand', 302),\n",
       " ('membres', 301),\n",
       " ('voie', 300),\n",
       " ('avis', 295),\n",
       " ('propose', 295),\n",
       " ('jours', 292),\n",
       " ('dernier', 290),\n",
       " ('recettes', 290),\n",
       " ('manière', 287),\n",
       " ('aucune', 287),\n",
       " ('ouvriers', 282),\n",
       " ('mesure', 281),\n",
       " ('hôtel', 278),\n",
       " ('chaque', 277),\n",
       " ('personnes', 275),\n",
       " ('faite', 275)]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe9bcc-5f4f-4fd6-a885-975699385737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
