{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7612caae-bf4a-4bae-8f4b-957bcba9a004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yake\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yake\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image\n",
    "\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "\n",
    "import sys\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import sys\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d65367f4-551a-4218-946f-1737c249716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "675dfa06-e1e6-4e87-8a7a-6b0446b8283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8136021-9927-40cb-b2f4-31d86aa9abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/txt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0981312-3c7a-4fcc-b0a5-d3d3c8cdfd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0c8d2-1335-4ebf-98a3-279189209f7a",
   "metadata": {},
   "source": [
    "## Choisir une décennie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a75160d0-4635-4865-86eb-b62d9ba1d1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DECADE = '1850'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1dd8e-d5e6-4bf0-9248-92b073965e09",
   "metadata": {},
   "source": [
    "## Charger tous les  fichiers de la décennie et en créer une liste de textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b8c1184-1276-418d-92c8-ca9cc985464c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bxl_1850_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1850_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1850_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1850_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1850_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1850_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1850_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1850_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1850_Tome_II1_Part_5.txt',\n",
       " 'Bxl_1850_Tome_II1_Part_6.txt',\n",
       " 'Bxl_1850_Tome_II1_Part_7.txt',\n",
       " 'Bxl_1851_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1851_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1851_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1851_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1851_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1851_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1851_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1851_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1851_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1851_Tome_II1_Part_5.txt',\n",
       " 'Bxl_1851_Tome_II1_Part_6.txt',\n",
       " 'Bxl_1851_Tome_II1_Part_7.txt',\n",
       " 'Bxl_1852_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1852_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1852_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1852_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1852_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1852_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1852_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1852_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1852_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1852_Tome_II1_Part_5.txt',\n",
       " 'Bxl_1854_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1854_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1854_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1854_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1854_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1854_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1854_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1854_Tome_II1_Part_5.txt',\n",
       " 'Bxl_1854_Tome_II1_Part_6.txt',\n",
       " 'Bxl_1855_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1855_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1855_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1855_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1855_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1855_Tome_I1_Part_6.txt',\n",
       " 'Bxl_1855_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1855_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1855_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1855_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1855_Tome_II1_Part_5.txt',\n",
       " 'Bxl_1855_Tome_II1_Part_6.txt',\n",
       " 'Bxl_1855_Tome_II1_Part_7.txt',\n",
       " 'Bxl_1856_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1856_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1856_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1856_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1856_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1856_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1856_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1856_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1856_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1856_Tome_II1_Part_5.txt',\n",
       " 'Bxl_1856_Tome_II1_Part_6.txt',\n",
       " 'Bxl_1856_Tome_II1_Part_7.txt',\n",
       " 'Bxl_1856_Tome_II1_Part_8.txt',\n",
       " 'Bxl_1857_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1857_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1857_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1857_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1857_Tome_I1_Part_5.txt',\n",
       " 'Bxl_1857_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1857_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1857_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1857_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1857_Tome_II1_Part_5.txt',\n",
       " 'Bxl_1857_Tome_II1_Part_6.txt',\n",
       " 'Bxl_1858_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1858_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1858_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1858_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1858_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1858_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1858_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1858_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1858_Tome_II1_Part_5.txt',\n",
       " 'Bxl_1859_Tome_I1_Part_1.txt',\n",
       " 'Bxl_1859_Tome_I1_Part_2.txt',\n",
       " 'Bxl_1859_Tome_I1_Part_3.txt',\n",
       " 'Bxl_1859_Tome_I1_Part_4.txt',\n",
       " 'Bxl_1859_Tome_II1_Part_1.txt',\n",
       " 'Bxl_1859_Tome_II1_Part_2.txt',\n",
       " 'Bxl_1859_Tome_II1_Part_3.txt',\n",
       " 'Bxl_1859_Tome_II1_Part_4.txt',\n",
       " 'Bxl_1859_Tome_II1_Part_5.txt']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_path = \"../data/txt/\"\n",
    "\n",
    "#files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]\n",
    "#print(files)\n",
    "\n",
    "# Lister les fichiers de cette année\n",
    "data_path = '../data'\n",
    "txt_path = '../data/txt'\n",
    "txts = [f for f in os.listdir(txt_path) if os.path.isfile(os.path.join(txt_path, f)) and f\"_{DECADE[:-1]}\" in f]\n",
    "txts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "deb16ee1-2472-4c9a-a0c6-d8107f59c90d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0c3b018-a348-428f-90d5-b024aa1df739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stocker le contenu de ces fichiers dans une liste\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(os.path.join(txt_path, txt), 'r') as f:\n",
    "        content_list.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6a867c8-48b8-4bc4-8abf-c9e423bc2c28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bxl_1850_Tome_I1_Part_1.txt'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer les 200 premiers caractères du contenu du premier fichier\n",
    "txts[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b5b2f9c-19b2-4021-9517-4ec25de6dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrire tout le contenu dans un fichier temporaire\n",
    "temp_path = '../data/tmp'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "with open(os.path.join(temp_path, f'{DECADE}.txt'), 'w') as f:\n",
    "    f.write(' '.join(content_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dec4332b-16c0-4c7d-b404-cca6e7910bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textract\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "544e06fd-758a-4cad-84e7-ed292a9e7aca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LLETIN COMMUNAL.\\nANNÉE 1850.\\n\\nPREMIER\\n\\nSEMESTRE,\\n\\nBRUXELLES,\\nOIS-WITTOI'CK\\n\\n,\\n\\nIMPlUMtVR\\n\\nDE\\n\\nLA\\n\\nVILLE,\\n\\n1U K\\n\\n\\\\V\\n\\nl\\n\\n\\x0clïi\\n\\n\\x0cVILLE\\n\\nDE\\n\\nBRUXELLES.\\n\\nBULLETIN COMMUNAL.\\nANNÉE 1 8 5 0 . —\\n\\nN° 1.\\n\\nTravaux publics. — Adjudications.\\n\\nLe Collège des Bourgmestre et Echevins de la ville de Bruxelles\\nProcédera, en séance publique, le mardi 5 février 1850, à une\\nheure de relevée, à l'ouverture des soumissions qui l u i seront présentées pour l'entreprise des travaux et fournitures désignés c i dessous, sa\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer le contenu du fichier et constater les \"déchets\"\n",
    "with open(os.path.join(temp_path, f'{DECADE}.txt'), 'r') as f:\n",
    "    before = f.read()\n",
    "\n",
    "before[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c2ce7-48ea-4b5e-a27b-e3c2d6534935",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61258ec4-a4bf-4894-87f8-f694377343cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"les\", \"plus\", \"cette\", \"fait\", \"faire\", \"être\", \"deux\", \"comme\", \"dont\", \"tout\", \n",
    "       \"ils\", \"bien\", \"sans\", \"peut\", \"tous\", \"après\", \"ainsi\", \"donc\", \"cet\", \"sous\",\n",
    "       \"celle\", \"entre\", \"encore\", \"toutes\", \"pendant\", \"moins\", \"dire\", \"cela\", \"non\",\n",
    "       \"faut\", \"trois\", \"aussi\", \"dit\", \"avoir\", \"doit\", \"contre\", \"depuis\", \"autres\",\n",
    "       \"van\", \"het\", \"autre\", \"jusqu\"]\n",
    "sw = set(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cf05d1cc-f880-4bd4-8185-b9c1589ad6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 stopwords:\n",
      " ['ai', 'aie', 'aient', 'aies', 'ainsi', 'ait', 'après', 'as', 'au', 'aura', 'aurai', 'auraient', 'aurais', 'aurait', 'auras', 'aurez', 'auriez', 'aurions', 'aurons', 'auront', 'aussi', 'autre', 'autres', 'aux', 'avaient', 'avais', 'avait', 'avec', 'avez', 'aviez', 'avions', 'avoir', 'avons', 'ayant', 'ayante', 'ayantes', 'ayants', 'ayez', 'ayons', 'bien', 'c', 'ce', 'cela', 'celle', 'ces', 'cet', 'cette', 'comme', 'contre', 'd', 'dans', 'de', 'depuis', 'des', 'deux', 'dire', 'dit', 'doit', 'donc', 'dont', 'du', 'elle', 'en', 'encore', 'entre', 'es', 'est', 'et', 'eu', 'eue', 'eues', 'eurent', 'eus', 'eusse', 'eussent', 'eusses', 'eussiez', 'eussions', 'eut', 'eux', 'eûmes', 'eût', 'eûtes', 'faire', 'fait', 'faut', 'furent', 'fus', 'fusse', 'fussent', 'fusses', 'fussiez', 'fussions', 'fut', 'fûmes', 'fût', 'fûtes', 'het', 'il', 'ils', 'j', 'je', 'jusqu', 'l', 'la', 'le', 'les', 'leur', 'lui', 'm', 'ma', 'mais', 'me', 'mes', 'moi', 'moins', 'mon', 'même', 'n', 'ne', 'non', 'nos', 'notre', 'nous', 'on', 'ont', 'ou', 'par', 'pas', 'pendant', 'peut', 'plus', 'pour', 'qu', 'que', 'qui', 's', 'sa', 'sans', 'se', 'sera', 'serai', 'seraient', 'serais', 'serait', 'seras', 'serez', 'seriez', 'serions', 'serons', 'seront', 'ses', 'soient', 'sois', 'soit', 'sommes', 'son', 'sont', 'sous', 'soyez', 'soyons', 'suis', 'sur', 't', 'ta', 'te', 'tes', 'toi', 'ton', 'tous', 'tout', 'toutes', 'trois', 'tu', 'un', 'une', 'van', 'vos', 'votre', 'vous', 'y', 'à', 'étaient', 'étais', 'était', 'étant', 'étante', 'étantes', 'étants', 'étiez', 'étions', 'été', 'étée', 'étées', 'étés', 'êtes', 'être']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(sw)} stopwords:\\n {sorted(sw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad36cb0-9ee5-4aa7-a25c-78af07e2e7ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b05e738c-f8d5-449e-b797-8723ec5915b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(DECADE, folder=None):\n",
    "    if folder is None:\n",
    "        input_path = f\"{DECADE}.txt\"\n",
    "        output_path = f\"{DECADE}_clean.txt\"\n",
    "    else:\n",
    "        input_path = f\"{folder}/{DECADE}.txt\"\n",
    "        output_path = f\"{folder}/{DECADE}_clean.txt\"\n",
    "    output = open(output_path, \"w\", encoding='utf-8')\n",
    "    with open(input_path, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        words = nltk.wordpunct_tokenize(text)\n",
    "        kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "        kept_string = \" \".join(kept)\n",
    "        output.write(kept_string)\n",
    "    return f'Output has been written in {output_path}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15ffc05a-089c-4f3f-8870-18371d92324c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output has been written in ../data/tmp/1850_clean.txt!'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(DECADE, folder=temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295005b-cae2-447a-bf45-22d1e0a81c99",
   "metadata": {},
   "source": [
    "## Counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "744b2516-e933-4554-a0ef-643cfe4dd51f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0  1196584 10067447 ../data/tmp/1850_clean.txt\n"
     ]
    }
   ],
   "source": [
    "## word's total number 1840\n",
    "!wc ../data/tmp/1850_clean.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a2f01-1a7c-49ad-bc26-6f47b8194728",
   "metadata": {},
   "source": [
    "## Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ed0dac8-837c-4e9e-91e9-7197599b98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du contenu du fichier\n",
    "txt_path = '../data/tmp/1850_clean.txt'\n",
    "limit = 10**8\n",
    "\n",
    "with open(txt_path) as f:\n",
    "    text = f.read()[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "722993c0-ff31-4a2b-862a-0de0e047f096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196584 words found\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "words = nltk.wordpunct_tokenize(text)\n",
    "print(f\"{len(words)} words found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "496d832d-66d4-4fcb-bee3-348b0f8ea348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196584 words kept (61142 different word forms)\n"
     ]
    }
   ],
   "source": [
    "# Eliminer les stopwords et les termes non alphabétiques\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852149e-d625-4cfd-97b9-9f7f02b718ba",
   "metadata": {},
   "source": [
    "## Finally couting related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27e45009-e520-4705-97fb-e6d9d10b4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = '../data/tmp/1850_clean.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "118824e1-e4f5-42ec-b584-eedd3aab9f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Le mot 'culture' apparaître 93 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cultures' apparaître 1266 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cultures' apparaître 3 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'théâtres' apparaître 209 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Théâtre' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Théâtres' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cultures' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Museum' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'museums' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Museums' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'musée' apparaître 100 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Musée' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'musées' apparaître 8 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Musées' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'espace culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Espace culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'espaces culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Espace de culture' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'espacee de culture' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'lieu culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Lieu culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'lieux culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Lieux culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'endroit culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'endroits culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'centre culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Centre culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'centres culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Centres culturels' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cinéma' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'patrimoine culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Patrimoine culturel' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cinémas' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Cinéma' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " 'Cinémas' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'Cinema' apparaître 0 fois dans le corpus\n",
      "\n",
      "\n",
      " Le mot 'cinema' apparaître 0 fois dans le corpus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = 'culture'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_culture = f.read().count(word)\n",
    "print(f\"\\n Le mot 'culture' apparaître {occurrence_culture} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'théâtre'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_théâtre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cultures' apparaître {occurrence_théâtre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'theatre'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_theatre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cultures' apparaître {occurrence_theatre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'théâtres'\n",
    "with open(txt_path) as f:\n",
    "    occurrence__theatres = f.read().count(word)\n",
    "print(f\"\\n Le mot 'théâtres' apparaître {occurrence__theatres} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Théâtre'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_theatre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Théâtre' apparaître {occurrence_theatre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Théâtres'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_theatre = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Théâtres' apparaître {occurrence_theatre} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'museum'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museum = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cultures' apparaître {occurrence_museum} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Museum'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museum = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Museum' apparaître {occurrence_museum} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'museums'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museums = f.read().count(word)\n",
    "print(f\"\\n Le mot 'museums' apparaître {occurrence_museums} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Museums'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_museums = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Museums' apparaître {occurrence_museums} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'musée'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musée = f.read().count(word)\n",
    "print(f\"\\n Le mot 'musée' apparaître {occurrence_musée} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'Musée'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musée = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Musée' apparaître {occurrence_musée} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'musées'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musées = f.read().count(word)\n",
    "print(f\"\\n Le mot 'musées' apparaître {occurrence_musées} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'Musées'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_musées = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Musées' apparaître {occurrence_musées} fois dans le corpus\\n\") \n",
    "\n",
    "word = 'espace culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_ec = f.read().count(word)\n",
    "print(f\"\\n 'espace culturel' apparaître {occurrence_ec} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Espace culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_ec = f.read().count(word)\n",
    "print(f\"\\n 'Espace culturel' apparaître {occurrence_ec} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'espaces culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_ecs = f.read().count(word)\n",
    "print(f\"\\n 'espaces culturels' apparaître {occurrence_ecs} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'espace de culture'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_edc = f.read().count(word)\n",
    "print(f\"\\n 'Espace de culture' apparaître {occurrence_edc} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'espaces de culture'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_esdc = f.read().count(word)\n",
    "print(f\"\\n 'espacee de culture' apparaître {occurrence_esdc} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'lieu culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieu = f.read().count(word)\n",
    "print(f\"\\n 'lieu culturel' apparaître {occurrence_lieu} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Lieu culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieu = f.read().count(word)\n",
    "print(f\"\\n 'Lieu culturel' apparaître {occurrence_lieu} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'lieux culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieux = f.read().count(word)\n",
    "print(f\"\\n 'lieux culturels' apparaître {occurrence_lieux} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Lieux culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_lieux = f.read().count(word)\n",
    "print(f\"\\n 'Lieux culturels' apparaître {occurrence_lieux} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'endroit culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_endcult = f.read().count(word)\n",
    "print(f\"\\n 'endroit culturel' apparaître {occurrence_endcult} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'endroits culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_endcults = f.read().count(word)\n",
    "print(f\"\\n 'endroits culturels' apparaître {occurrence_endcults} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'centre culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centre_culturel = f.read().count(word)\n",
    "print(f\"\\n 'centre culturel' apparaître {occurrence_centre_culturel} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Centre culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centre_culturel = f.read().count(word)\n",
    "print(f\"\\n 'Centre culturel' apparaître {occurrence_centre_culturel} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'centres culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centres_culturels = f.read().count(word)\n",
    "print(f\"\\n 'centres culturels' apparaître {occurrence_centres_culturels} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Centres culturels'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_centres_culturels = f.read().count(word)\n",
    "print(f\"\\n 'Centres culturels' apparaître {occurrence_centres_culturels} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'cinéma'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinema = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cinéma' apparaître {occurrence_cinema} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'patrimoine culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_patrimoine = f.read().count(word)\n",
    "print(f\"\\n 'patrimoine culturel' apparaître {occurrence_patrimoine} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Patrimoine culturel'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_patrimoinec = f.read().count(word)\n",
    "print(f\"\\n 'Patrimoine culturel' apparaître {occurrence_patrimoinec} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'cinémas'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinema = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cinémas' apparaître {occurrence_cinema} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Cinéma'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinemaC = f.read().count(word)\n",
    "print(f\"\\n 'Cinéma' apparaître {occurrence_cinemaC} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Cinémas'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_cinemaCs = f.read().count(word)\n",
    "print(f\"\\n 'Cinémas' apparaître {occurrence_cinemaCs} fois dans le corpus\\n\")\n",
    "\n",
    "word = 'Cinema'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_avencine = f.read().count(word)\n",
    "print(f\"\\n Le mot 'Cinema' apparaître {occurrence_avencine } fois dans le corpus\\n\")\n",
    "\n",
    "word = 'cinema'\n",
    "with open(txt_path) as f:\n",
    "    occurrence_avencine = f.read().count(word)\n",
    "print(f\"\\n Le mot 'cinema' apparaître {occurrence_avencine } fois dans le corpus\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b829b0-0fe2-4f12-bdec-c87c57d1161f",
   "metadata": {},
   "source": [
    "## Vérifier les 100 mots les plus fréquents  - liée au sujet recherché ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a13abd7-88bb-4747-9794-34ba930d1632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bourgmestre',\n",
       " 'Bruxelles',\n",
       " 'Collège',\n",
       " 'Conseil',\n",
       " 'D E S BIENS',\n",
       " 'Den Nest',\n",
       " 'DÉSIGNATION D E S BIENS',\n",
       " 'Messieurs',\n",
       " 'Remerciements',\n",
       " 'VILLE',\n",
       " 'art',\n",
       " 'avons',\n",
       " 'boni recette dépense',\n",
       " 'bourgmestre',\n",
       " 'bruxelles',\n",
       " \"c'est\",\n",
       " 'chapitre',\n",
       " 'collège',\n",
       " 'commune',\n",
       " 'conseil',\n",
       " 'conseil communal',\n",
       " 'conseil général',\n",
       " 'c’est',\n",
       " \"d'un\",\n",
       " \"d'une\",\n",
       " 'den Nest',\n",
       " 'depenses dépenses recettes',\n",
       " 'dit',\n",
       " 'déficit recette dépense',\n",
       " 'dépense',\n",
       " 'dépense recette boni',\n",
       " 'dépenses',\n",
       " 'dépenses dépenses',\n",
       " 'dépenses dépenses prévues',\n",
       " \"dépenses ordinaires qu'on\",\n",
       " 'd’une',\n",
       " 'francs',\n",
       " 'général',\n",
       " \"l'article\",\n",
       " 'mais',\n",
       " 'messieurs',\n",
       " 'n’est',\n",
       " 'ordinaires',\n",
       " 'p r é',\n",
       " 'prix',\n",
       " \"q u ' i\",\n",
       " 'q u e',\n",
       " 'q u i',\n",
       " 'q u é',\n",
       " \"qu'on\",\n",
       " 'question',\n",
       " 'qu’il',\n",
       " 'recette dépense',\n",
       " 'recette dépense prévue',\n",
       " 'recettes imprévues. dépenses',\n",
       " 'recettes recettes',\n",
       " 'rue',\n",
       " 'sacrés ordinaires',\n",
       " 'services',\n",
       " 'titres',\n",
       " 'total',\n",
       " 'vases sacrés ordinaires',\n",
       " 'ville',\n",
       " 'vue',\n",
       " 'é d i t',\n",
       " 'é p a r',\n",
       " 'é t r ',\n",
       " 'é t é',\n",
       " 'ê t r',\n",
       " 'œ u v r e'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création d'une liste de mots à ignorer\n",
    "ignored = set([\"Collège\", \"collège\", \"francs\", \"Bourgmestre\",\"Messieurs\",\"VILLE\", \"Conseil\", \"conseil communal\", \n",
    "               \"conseil général\", \"conseil\", \"conseil communal\", \"général\", \"d'un\",\"d'une\", \"c'est\", \"ordinaires\", \n",
    "               \"chapitre\", \"titres\", \"recette dépense\", \"services\", \"dépenses\", \"dépense\", \"dépenses dépenses prévues\", \n",
    "               \"déficit recette dépense\", \"recette dépense prévue\", \"boni recette dépense\", \"dépense recette boni\", \n",
    "               \"recettes recettes\", \"dépenses dépenses\", \"qu'on\", \"depenses dépenses recettes\", \n",
    "               \"vases sacrés ordinaires\", \"sacrés ordinaires\", \"dépenses ordinaires qu'on\", \n",
    "               \"depenses dépenses recettes\", \"recettes imprévues. dépenses\", \"dit\", \"vue\", \"n’est\", \"avons\", \n",
    "               \"d’une\",\"rue\", \"Den Nest\", \"commune\", \"qu’il\", \"question\", \"ville\", \"c’est\", \"mais\", \"den Nest\", \n",
    "               \"total\", \"art\", \"l'article\", \"Bourgmestre\", \"bourgmestre\", \"Messieurs\", \"VILLE\", \"prix\", \"Bruxelles\",\n",
    "               \"bruxelles\", \"messieurs\", \"é p a r\", \"é d i t\", \"p r é\", \"q u é\", \"é t é\", \"q u i\", \"q u ' i\", \"ê t r\", \n",
    "               \"œ u v r e\", \"D E S BIENS\", \"Remerciements\", \"q u e\",\"DÉSIGNATION D E S BIENS\", \"é t r \"])\n",
    "ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8ad83c1f-90a8-4b55-bb96-03fef5772955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117484 words kept (61121 different word forms)\n"
     ]
    }
   ],
   "source": [
    "# Eliminer les stopwords et les termes non alphabétiques\n",
    "kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw and w not in ignored]\n",
    "voc = set(kept)\n",
    "print(f\"{len(kept)} words kept ({len(voc)} different word forms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ffc90bf2-f890-48e1-abb2-97ee4312b900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('section', 7174),\n",
       " ('travaux', 4870),\n",
       " ('rapport', 4241),\n",
       " ('administration', 4186),\n",
       " ('hospices', 3673),\n",
       " ('place', 3337),\n",
       " ('projet', 2986),\n",
       " ('séance', 2952),\n",
       " ('police', 2811),\n",
       " ('service', 2635),\n",
       " ('demande', 2604),\n",
       " ('partie', 2593),\n",
       " ('nombre', 2530),\n",
       " ('année', 2467),\n",
       " ('lieu', 2464),\n",
       " ('frais', 2431),\n",
       " ('mètres', 2416),\n",
       " ('somme', 2387),\n",
       " ('publics', 2386),\n",
       " ('enfants', 2329),\n",
       " ('finances', 2314),\n",
       " ('hôtel', 2257),\n",
       " ('chez', 2191),\n",
       " ('proposition', 2174),\n",
       " ('compte', 2141),\n",
       " ('heures', 2100),\n",
       " ('publique', 2019),\n",
       " ('eau', 1927),\n",
       " ('mois', 1921),\n",
       " ('état', 1910),\n",
       " ('communal', 1893),\n",
       " ('haute', 1859),\n",
       " ('avis', 1844),\n",
       " ('secours', 1841),\n",
       " ('ceux', 1821),\n",
       " ('elles', 1713),\n",
       " ('budget', 1704),\n",
       " ('propose', 1696),\n",
       " ('voitures', 1695),\n",
       " ('leurs', 1671),\n",
       " ('celui', 1646),\n",
       " ('approbation', 1642),\n",
       " ('rues', 1631),\n",
       " ('discussion', 1614),\n",
       " ('construction', 1611),\n",
       " ('avant', 1608),\n",
       " ('droit', 1602),\n",
       " ('toute', 1596),\n",
       " ('grande', 1592),\n",
       " ('loi', 1589),\n",
       " ('ans', 1576),\n",
       " ('procès', 1565),\n",
       " ('plan', 1554),\n",
       " ('exécution', 1547),\n",
       " ('grand', 1490),\n",
       " ('porte', 1488),\n",
       " ('cas', 1483),\n",
       " ('parce', 1480),\n",
       " ('jean', 1473),\n",
       " ('église', 1436),\n",
       " ('recettes', 1428),\n",
       " ('établissement', 1399),\n",
       " ('maisons', 1390),\n",
       " ('hospice', 1386),\n",
       " ('très', 1377),\n",
       " ('donner', 1367),\n",
       " ('jour', 1360),\n",
       " ('dernier', 1353),\n",
       " ('conclusions', 1351),\n",
       " ('point', 1346),\n",
       " ('article', 1335),\n",
       " ('quelques', 1323),\n",
       " ('règlement', 1318),\n",
       " ('commission', 1316),\n",
       " ('bois', 1309),\n",
       " ('flandre', 1303),\n",
       " ('dépôt', 1299),\n",
       " ('subside', 1295),\n",
       " ('honorable', 1289),\n",
       " ('temps', 1284),\n",
       " ('entretien', 1280),\n",
       " ('suivant', 1274),\n",
       " ('quand', 1268),\n",
       " ('janvier', 1265),\n",
       " ('peu', 1233),\n",
       " ('voie', 1233),\n",
       " ('société', 1231),\n",
       " ('gouvernement', 1228),\n",
       " ('pain', 1221),\n",
       " ('communale', 1218),\n",
       " ('saint', 1218),\n",
       " ('arrêté', 1217),\n",
       " ('part', 1215),\n",
       " ('chaque', 1209),\n",
       " ('agit', 1201),\n",
       " ('marché', 1195),\n",
       " ('cent', 1195),\n",
       " ('maison', 1194),\n",
       " ('hui', 1190),\n",
       " ('sieur', 1185)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(kept)\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f12fe5-daeb-4cc5-96ea-e2fe9f30909d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
